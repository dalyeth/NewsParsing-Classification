##  LSTM with pretrained bert sentence embeddings for news classification (9 topics) and fake title generation (with FastAPI) 
project report https://github.com/dalyeth/NewsParsing-Classification-SeqGeneration/blob/main/Project%20Report.pdf


Проект для классификации новостных статей на русском языке и генерации новостных заголовков с реализацией веб-приложения

Цели проекта: собрать на базе RNN рабочий классификатор новостных статей, реализовать генератор новостных заголовков, реализовать веб-сервис на базе FastAPI

## Задачи, решенные в проекте:
* парсинг и подготовка корпуса статей
   ### Классификатор
* интеграция предобученных эмбеддингов предложений, реализация пользовательского класса датасета
* реализация пользовательского класса и методов обучения и последующей оценки классификатора на базе RNN
* успешное обучение и сериализация классификатора
   ### Генератор
* реализация пользовательского класса датасета, создание датасета на базе токенизатора rubert-tiny2
* реализация пользовательского класса и методов обучения и последующей оценки модели на базе RNN
* успешное обучение и сериализация модели
* реализация генератора случайных заголовков на базе последовательного применения topk и beam search

## Данные: 
В качестве обучающего корпуса были использованы архивы новостей с сайтов lenta.ru, iz.ru, ria.ru, собранные в рамках соревнования https://www.kaggle.com/competitions/news-scraping-competition.

Парсеры для них лежат в текущем репозитории в отдельных блокнотах. 

Архивы расшарены здесь: https://drive.google.com/drive/folders/1X3zd3zjTv6-Bho3z3FpCAoByM0N2PNro?usp=sharing 

Категории статей: Здоровье/Забота о себе, Происшествия/Силовые структуры, Страны бывшего СССР, Наука, Спорт, Туризм/Путешествия, Общество, Экономика, Строительство/Недвижимость

  #### Классификатор
Статьи из разных источников были объединены по категориям, выборка была проверена на дубликаты и сбалансирована:  по каждой теме случайным образом было отобрано число статей, соответствуюеще минимальному числу статей в категории. 
Для двух неспецифичных категорий, с которыми классификатор во время обучения справлялся хуже других, пропорция была кратно увеличена. 25% документов было отложено для тестирования, остальная часть была поделена на обучающую и 
валидационную в соотношении 9/1. При разделении использовалась стратификация по целевому признаку для сохранения распределения категорий в каждой подвыборке.  

  #### Генератор
Использовались все собранные заголовки без учета категорий. 

## Метрики: 
Классификатор - f1-score, precision, recall, accuracy

Генератор - perplexity

## Эмбеддинги
#### Классификатор
В качестве эмбеддингов были использованы предобученные эмбеддинги предложений из модели rubert-tiny2 размерностью 312. 

Тексты статей были разбиты на предложения с помощью парсера spacy, все тексты приведены к длине 50 (беглый анализ показал. что подавляющее большинство текстов в это число укладывается). 

На вход LSTM подавались эмбеддинги предложений. На вход классификатору подавался усредненный вектор, прошедший через функцию активации. 

#### Генератор
В качестве словаря был использован словарь модели rubert-tiny2, эмбеддинги обучались посредством nn.Embedding. 


# Классификатор 
### Архитектура модели
двунаправленный LSTM с 4 слоями и дропаутом, гиперболический тангенс в качестве функции активации и выходной полносвязный слой

### Обучение
Обучение проводилось в несколько разнесенных по времени заходов, совокупно модель обучалась около 20 эпох. Обучение остановлено, когда метрики на валидационной выборке начали ухудшаться.  

оптимизатор AdamW, функция потерь CrossEntropyLoss()

### Результаты и выводы
Метрики на отложенной выборке свидетельствуют о том, что классификатор обучился, 85% считаем приемлемым порогом.

Только у трех неспецифичных категорий (Общество, Силовые структуры и Страны бывшего СССР) f-score менее 85%, вероятно, его можно еще улучшить, увеличив их долю в обучающей выборке.  
               
                precision    recall  f1-score   support
           0       0.82      0.71      0.76      9164
           1       0.84      0.88      0.86      3054
           2       0.78      0.85      0.82      6109
           3       0.74      0.82      0.78      3055
           4       0.97      0.95      0.96      3055
           5       0.89      0.93      0.91      3055
           6       0.93      0.95      0.94      3054
           7       0.86      0.94      0.90      3054
           8       0.89      0.85      0.87      3054
    accuracy        -         -        0.84     36654
    macro avg      0.86      0.87      0.87     36654
    weighted avg   0.85      0.84      0.84     36654


Классификатор уступает классификаторам на базе трансформеров, но требует и ощутимо меньше ресурсов и времени на обучение и дает в целом приемлемое и ровное качество классификации по всем категориям. 

# Генератор
### Архитектура модели: 

  (embedding): Embedding(83828, 2048)

  
  (rnn): LSTM(2048, 512, num_layers=2, batch_first=True, dropout=0.3)

  
  (linear): Linear(in_features=512, out_features=512, bias=True)

  
  (projection): Linear(in_features=512, out_features=83828, bias=True)

  
  (func): Tanh()

  
  (dropout): Dropout(p=0.1, inplace=False)


## Обучение 
Обучение в несколько итераций совокупно 12 эпох. Остановлено, когда перплексия на валидационной выборке начала расти, а качество сгенерированных предложений - субъективно ухудшаться. 

оптимизато Adam, функция потерь CrossEntropyLoss()

## Результаты и выводы
Максимально достигнутая перплексия на валидационной выборке 113, на тестовой выборке модель показала перплексию 115. 

Для генерации образцов  использовались как topk-алгоритм, так и beam search. Первый давал хорошую вариативность и удачные неожиданные сочетания, но связи заметно ослабевали с увеличением длины предложения, процент некорректных предложений оставался высоким. Второй при грамматичеки корректных и связных предложениях выдавал ограниченое число повторяющихся вариантов и очень  замедлялся при попытках увеличить число вариантов. 

Итоговая функция генерации совмещает оба подхода: для генерации первых токенов после стартовой последовательности используется topk, для окончания предложения - beam search. 

## FastAPI
Для каждого из проектов был реализован независимый web-сервис на базе FastAPI 

Предобученные модели здесь https://drive.google.com/drive/folders/1XjTdqggBd_r_fWjQSyBOGI4032oQfrhO?usp=sharing

Для запуска нужно скопировать соответствующую модель в папку model выбранного проекта. python vesion == 3.10 

Классификатор принимает на вход документ csv и название колонки с текстом. Для демо значение column_name должно быть text. Файл demo.csv в папке проекта Classifier

Генератор принимает в качестве параметров стартовую секвенцию и количество заголовков, которые требуется сгенерировать  


