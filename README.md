# a bidirectional LSTM with pretrained bert sentence embeddings for news classification (9 topics) 

Тренировочный проект для классификации новостных статей на русском языке (по мотивам соревнования https://www.kaggle.com/competitions/news-scraping-competition)

Цель проекта: собрать на базе RNN рабочий классификатор новостных статей

# Задачи, решенные в проекте:
1) парсинг и подготовка корпуса статей
2) интеграция предобученных эмбеддингов предложений, реализация пользовательского класса датасета
3) реализация пользовательского класса и методов обучения и последующей оценки классификатора на базе RNN
4) успешное обучение и сериализация классификатора
   

# Данные: 
В качестве обучающего корпуса были использованы архивы новостей с сайтов lenta.ru, iz.ru, ria.ru. Парсеры для них лежат в текущем репозитории в отдельных блокнотах. 

Архивы расшарены здесь: https://drive.google.com/drive/folders/1X3zd3zjTv6-Bho3z3FpCAoByM0N2PNro?usp=sharing 

Категории статей: Здоровье/Забота о себе, Происшествия/Силовые структуры, Страны бывшего СССР, Наука, Спорт, Туризм/Путешествия, Общество, Экономика, Строительство/Недвижимость

Статьи из разных источников были объединены по категориям, выборка была проверена на дубликаты и сбалансирована: по каждой теме случайным образом было отобрано число статей, соответствуюеще минимальному числу статей в категории. 

Для двух неспецифичных категорий, с которыми классификатор во время обучения справлялся хуже других, пропорция была кратно увеличена. 25% документов было отложено для тестирования, остальная часть была поделена на обучающую и 
валидационную в соотношении 9/1. При разделении использовалась стратификация по целевому признаку для сохранения распределения категорий в каждой подвыборке.  

# Метрики: 
f1-score, precision, recall, accuracy

# Эмбеддинги
В качестве эмбеддингов были использованы предобученные эмбеддинги предложений из модели rubert-tiny2 размерностью 312. 

Тексты статей были разбиты на предложения с помощью парсера spacy, все тексты приведены к длине 50 (беглый анализ показал. что подавляющее большинство текстов в это число укладывается). 

На вход LSTM подавались эмбеддинги предложений. На вход классификатору подавался усредненный вектор, прошедший через функцию активации. 

# Архитектура модели
двунаправленный LSTM с 4 слоями и дропаутом, гиперболический тангенс в качестве функции активации и выходной полносвязный слой

# Обучение
Обучение с распараллеливанием на GPU, в несколько разнесенных по времени заходов, всего модель около 20 эпох. Остановлено, когда метрики на валидационной выборке начали ухудшаться.  

оптимизатор AdamW, функция потерь CrossEntropyLoss()

# Результаты и выводы
Метрики на отложенной выборке свидетельствуют о том, что классификатор обучился, 85% считаем приемлемым порогом.

Только у трех неспецифичных категорий (Общество, Силовые структуры и Страны бывшего СССР) f-score менее 85%, вероятно, его можно еще улучшить, увеличив их долю в обучающей выборке.  
               
                precision    recall  f1-score   support
           0       0.82      0.71      0.76      9164
           1       0.84      0.88      0.86      3054
           2       0.78      0.85      0.82      6109
           3       0.74      0.82      0.78      3055
           4       0.97      0.95      0.96      3055
           5       0.89      0.93      0.91      3055
           6       0.93      0.95      0.94      3054
           7       0.86      0.94      0.90      3054
           8       0.89      0.85      0.87      3054
    accuracy        -         -        0.84     36654
    macro avg      0.86      0.87      0.87     36654
    weighted avg   0.85      0.84      0.84     36654


Классификатор уступает классификаторам на базе трансформеров, но требует и ощутимо меньше ресурсов и времени на обучение и дает в целом приемлемое и ровное качество классификации по всем категориям. 

