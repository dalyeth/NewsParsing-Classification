{"metadata":{"colab":{"provenance":[]},"interpreter":{"hash":"403959ecd139c89f35081fab3d0ca535dfc149adc8a1d47a6d44f830632776ba"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7266269,"sourceType":"datasetVersion","datasetId":4211743},{"sourceId":7268608,"sourceType":"datasetVersion","datasetId":4213445},{"sourceId":7288372,"sourceType":"datasetVersion","datasetId":4226707},{"sourceId":7342920,"sourceType":"datasetVersion","datasetId":4263583},{"sourceId":7356108,"sourceType":"datasetVersion","datasetId":4269492},{"sourceId":158014709,"sourceType":"kernelVersion"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom collections import Counter\nimport fasttext\nfrom torch.utils.data import (TensorDataset, DataLoader, RandomSampler, SequentialSampler)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n\n#Torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n#BERT\nfrom transformers import BertTokenizer\nfrom transformers import BertForSequenceClassification\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\n\nimport re\nimport numpy as np\nimport math\nfrom functools import reduce\n\nimport time\nimport datetime\nimport warnings\nfrom tqdm import tqdm\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nfrom sklearn.preprocessing import normalize\n\n\n#import nltk\n#nltk.download('stopwords')\n#nltk.download('punkt')\n#nltk.download('snowball_data')\n#nltk.download('perluniprops')\n#nltk.download('universal_tagset')\n#nltk.download('stopwords')\n#nltk.download('nonbreaking_prefixes')\n#nltk.download('wordnet')\n#from nltk import tokenize\n#from nltk.tokenize import word_tokenize\n\nimport time\nimport random\nimport gc","metadata":{"execution":{"iopub.status.busy":"2024-01-07T08:54:17.681633Z","iopub.execute_input":"2024-01-07T08:54:17.681997Z","iopub.status.idle":"2024-01-07T08:54:17.691283Z","shell.execute_reply.started":"2024-01-07T08:54:17.681969Z","shell.execute_reply":"2024-01-07T08:54:17.690365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"test_news = pd.read_csv('/kaggle/input/testnews/test_news.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T18:08:24.668282Z","iopub.execute_input":"2024-01-06T18:08:24.669017Z","iopub.status.idle":"2024-01-06T18:08:26.496892Z","shell.execute_reply.started":"2024-01-06T18:08:24.668984Z","shell.execute_reply":"2024-01-06T18:08:26.496144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lenta.ru\ncare = pd.read_csv('/kaggle/input/lentaru/care_lenta_2012-03-01_2023-12-22.csv') #5\nussr = pd.read_csv('/kaggle/input/lentaru/ex_ussr_lenta_2012-03-01_2023-12-22.csv') #3\npolice = pd.read_csv('/kaggle/input/lentaru/police_lenta_2012-03-01_2023-12-22.csv') #2\nscience = pd.read_csv('/kaggle/input/lentaru/science_lenta_2012-03-01_2023-12-22.csv')#8\nsport = pd.read_csv('/kaggle/input/lentaru/sport_lenta_2012-03-01_2023-12-22.csv') #4\ntourism = pd.read_csv('/kaggle/input/lentaru/tourism_lenta_2012-03-01_2023-12-22.csv') #7\nsociety= pd.read_csv('/kaggle/input/lentaru/society_lenta_2012-03-01_2023-12-22.csv') #0\neconomy = pd.read_csv('/kaggle/input/lentaru/economy_lenta_2012-03-01_2023-12-22.csv') #1","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:31:19.291342Z","iopub.execute_input":"2024-01-05T12:31:19.291637Z","iopub.status.idle":"2024-01-05T12:31:59.178987Z","shell.execute_reply.started":"2024-01-05T12:31:19.291613Z","shell.execute_reply":"2024-01-05T12:31:59.177957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ria.ru\nrealty_list = !ls /kaggle/input/ria-custom-topics/ria_realty\nconstruction_list = !ls /kaggle/input/ria-custom-topics/ria_construction\nhealth_list = !ls /kaggle/input/ria-custom-topics/ria_health\nsociety_list= !ls /kaggle/input/ria-custom-topics/ria_society\n\ncat_dict = {'realty':'ria_realty/', 'construction':'ria_construction/', 'health':'ria_health/', 'society' :'ria_society/'}\n\nbase = '/kaggle/input/ria-custom-topics/'\n\ndef clean_ria_source(somestring):\n    pat = re.compile('([-—]\\sРИА\\sН(едвижимость|овости)\\.)|(\\/\\sРадио\\sSputnik\\.)|(\\n)')\n    somestring = re.sub(pat, '', somestring)\n    return somestring\n\ndef ria_set(some, cat):\n    res = pd.DataFrame()\n    for item in some:\n        res = pd.concat([pd.read_csv(base+cat_dict[cat]+str(item)), res])\n    res = res.rename(columns={'id': 'docid', 'content':'text'})\n    res['text'] =  res['text'].apply(lambda x: clean_ria_source(x))\n    return res","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:31:59.181358Z","iopub.execute_input":"2024-01-05T12:31:59.181642Z","iopub.status.idle":"2024-01-05T12:31:59.254743Z","shell.execute_reply.started":"2024-01-05T12:31:59.181619Z","shell.execute_reply":"2024-01-05T12:31:59.254047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"realty = ria_set(realty_list, 'realty')\nconstruction = ria_set(construction_list, 'construction')\nhealth = ria_set(health_list, 'health')\nria_society = ria_set(society_list, 'society')","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:31:59.255729Z","iopub.execute_input":"2024-01-05T12:31:59.255968Z","iopub.status.idle":"2024-01-05T12:32:08.419086Z","shell.execute_reply.started":"2024-01-05T12:31:59.255947Z","shell.execute_reply":"2024-01-05T12:32:08.418260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#iz.ru\nconstruction_list_iz = !ls /kaggle/input/iz-construction\nbase = '/kaggle/input/iz-construction/'\nres = pd.DataFrame()\nfor item in construction_list_iz:\n     res = pd.concat([pd.read_csv(base+str(item)), res])\n        \nconstruction_iz = res.rename(columns={'id': 'docid', 'content':'text'})\nconstruction_iz['text'] =  construction_iz['text'].apply(lambda x: clean_ria_source(x))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:08.421499Z","iopub.execute_input":"2024-01-05T12:32:08.422225Z","iopub.status.idle":"2024-01-05T12:32:09.676932Z","shell.execute_reply.started":"2024-01-05T12:32:08.422188Z","shell.execute_reply":"2024-01-05T12:32:09.676049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"construction_iz.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T10:00:56.727258Z","iopub.execute_input":"2024-01-05T10:00:56.727688Z","iopub.status.idle":"2024-01-05T10:00:56.744201Z","shell.execute_reply.started":"2024-01-05T10:00:56.727652Z","shell.execute_reply":"2024-01-05T10:00:56.741960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"construction_iz['text']","metadata":{"execution":{"iopub.status.busy":"2024-01-05T10:01:53.695429Z","iopub.execute_input":"2024-01-05T10:01:53.695884Z","iopub.status.idle":"2024-01-05T10:01:53.707076Z","shell.execute_reply.started":"2024-01-05T10:01:53.695849Z","shell.execute_reply":"2024-01-05T10:01:53.705382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"realty['text']","metadata":{"execution":{"iopub.status.busy":"2024-01-05T09:48:25.294071Z","iopub.execute_input":"2024-01-05T09:48:25.294491Z","iopub.status.idle":"2024-01-05T09:48:25.305334Z","shell.execute_reply.started":"2024-01-05T09:48:25.294440Z","shell.execute_reply":"2024-01-05T09:48:25.304056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"realty = pd.concat([realty, construction, construction_iz], ignore_index=True)\nsociety = pd.concat([society, ria_society], ignore_index=True)\ncare = pd.concat([health, care], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:16.712356Z","iopub.execute_input":"2024-01-05T12:32:16.713262Z","iopub.status.idle":"2024-01-05T12:32:16.772146Z","shell.execute_reply.started":"2024-01-05T12:32:16.713226Z","shell.execute_reply":"2024-01-05T12:32:16.771372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"care.loc[:, 'target'] = 5\nussr.loc[:, 'target'] = 3\npolice.loc[:, 'target'] = 2\nscience.loc[:, 'target'] = 8\nsport.loc[:, 'target'] = 4\ntourism.loc[:, 'target'] = 7\nsociety.loc[:, 'target'] = 0\neconomy.loc[:, 'target'] = 1\nrealty.loc[:, 'target'] = 6\n","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:18.831296Z","iopub.execute_input":"2024-01-05T12:32:18.832059Z","iopub.status.idle":"2024-01-05T12:32:18.846317Z","shell.execute_reply.started":"2024-01-05T12:32:18.831990Z","shell.execute_reply":"2024-01-05T12:32:18.845144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"realty.drop_duplicates(['text', 'title'], inplace=True)\ncare.drop_duplicates(['text', 'title'], inplace=True)\nsociety.drop_duplicates(['text', 'title'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:20.987402Z","iopub.execute_input":"2024-01-05T12:32:20.987799Z","iopub.status.idle":"2024-01-05T12:32:23.060264Z","shell.execute_reply.started":"2024-01-05T12:32:20.987767Z","shell.execute_reply":"2024-01-05T12:32:23.059174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lens = []\nfor item in [care, ussr, police, science, sport, tourism, society, economy, realty]:\n    lens.append(len(item))\nlens","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:23.171104Z","iopub.execute_input":"2024-01-05T12:32:23.171520Z","iopub.status.idle":"2024-01-05T12:32:23.180295Z","shell.execute_reply.started":"2024-01-05T12:32:23.171488Z","shell.execute_reply":"2024-01-05T12:32:23.179153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minlen = min(lens)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:25.428748Z","iopub.execute_input":"2024-01-05T12:32:25.429702Z","iopub.status.idle":"2024-01-05T12:32:25.433763Z","shell.execute_reply.started":"2024-01-05T12:32:25.429671Z","shell.execute_reply":"2024-01-05T12:32:25.432782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#балансируем обучающую выборку\nn = minlen\ncare =  care.sample(n)\nussr = ussr.sample(n)\npolice = police.sample(int(2*n))\nscience = science.sample(n)\nsport = sport.sample(n)\ntourism = tourism.sample(n)\nsociety = society.sample(3*n)\neconomy = economy.sample(n)\nrealty = realty.sample(n)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:27.361357Z","iopub.execute_input":"2024-01-05T12:32:27.362090Z","iopub.status.idle":"2024-01-05T12:32:27.785539Z","shell.execute_reply.started":"2024-01-05T12:32:27.362057Z","shell.execute_reply":"2024-01-05T12:32:27.784598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_keep = ['docid','url', 'title', 'text', 'target']","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:30.348467Z","iopub.execute_input":"2024-01-05T12:32:30.349294Z","iopub.status.idle":"2024-01-05T12:32:30.354481Z","shell.execute_reply.started":"2024-01-05T12:32:30.349255Z","shell.execute_reply":"2024-01-05T12:32:30.353357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([care, ussr, police, science, sport, tourism, society, economy, realty], ignore_index=True)\ndf = df[cols_to_keep]","metadata":{"execution":{"iopub.status.busy":"2024-01-05T12:32:32.195886Z","iopub.execute_input":"2024-01-05T12:32:32.196795Z","iopub.status.idle":"2024-01-05T12:32:32.340984Z","shell.execute_reply.started":"2024-01-05T12:32:32.196758Z","shell.execute_reply":"2024-01-05T12:32:32.340136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-06T18:09:07.644056Z","iopub.execute_input":"2024-01-06T18:09:07.644878Z","iopub.status.idle":"2024-01-06T18:09:07.663022Z","shell.execute_reply.started":"2024-01-06T18:09:07.644842Z","shell.execute_reply":"2024-01-06T18:09:07.662063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().any().sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T10:04:07.569086Z","iopub.execute_input":"2024-01-05T10:04:07.569605Z","iopub.status.idle":"2024-01-05T10:04:07.669129Z","shell.execute_reply.started":"2024-01-05T10:04:07.569562Z","shell.execute_reply":"2024-01-05T10:04:07.667812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T10:04:11.905484Z","iopub.execute_input":"2024-01-05T10:04:11.906311Z","iopub.status.idle":"2024-01-05T10:04:11.921249Z","shell.execute_reply.started":"2024-01-05T10:04:11.906268Z","shell.execute_reply":"2024-01-05T10:04:11.919556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train, data_test = train_test_split(df, stratify=df['target'], test_size=0.1, random_state = 112)","metadata":{"execution":{"iopub.status.busy":"2024-01-06T18:49:28.583665Z","iopub.execute_input":"2024-01-06T18:49:28.583961Z","iopub.status.idle":"2024-01-06T18:49:28.688822Z","shell.execute_reply.started":"2024-01-06T18:49:28.583935Z","shell.execute_reply":"2024-01-06T18:49:28.687833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.to_csv('data_train.csv')\ndata_test.to_csv('data_test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-06T10:14:06.998415Z","iopub.execute_input":"2024-01-06T10:14:06.998791Z","iopub.status.idle":"2024-01-06T10:14:18.529442Z","shell.execute_reply.started":"2024-01-06T10:14:06.998761Z","shell.execute_reply":"2024-01-06T10:14:18.528534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## BERT","metadata":{}},{"cell_type":"code","source":"MAX_LEN = 2048\nMODEL_PATH = 'cointegrated/rubert-tiny2'\nEPOCHS = 1\nBATCH_SIZE=2\nSAVE_PATH = '/kaggle/working/tynyrubert2.pt'\n","metadata":{"execution":{"iopub.status.busy":"2024-01-06T10:11:58.947517Z","iopub.execute_input":"2024-01-06T10:11:58.947862Z","iopub.status.idle":"2024-01-06T10:11:58.952594Z","shell.execute_reply.started":"2024-01-06T10:11:58.947835Z","shell.execute_reply":"2024-01-06T10:11:58.951505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom torch.utils.data import Dataset\n\nclass CustomDataset(Dataset):\n\n    def __init__(self, texts, targets, tokenizer, max_len=MAX_LEN):\n        self.texts = texts\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        target = self.targets[idx]\n\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',\n            return_attention_mask=True,\n            truncation=True,\n            return_tensors='pt',\n        )\n\n        return {\n           'text': text,\n           'input_ids': encoding['input_ids'].flatten(),\n           'attention_mask': encoding['attention_mask'].flatten(),\n           'targets': torch.tensor(target, dtype=torch.long)\n            }","metadata":{"execution":{"iopub.status.busy":"2024-01-06T10:14:18.531225Z","iopub.execute_input":"2024-01-06T10:14:18.531879Z","iopub.status.idle":"2024-01-06T10:14:18.541197Z","shell.execute_reply.started":"2024-01-06T10:14:18.531840Z","shell.execute_reply":"2024-01-06T10:14:18.540185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertClassifier:\n\n    def __init__(self, model_path=MODEL_PATH, tokenizer_path=MODEL_PATH, n_classes=9, epochs=EPOCHS, model_save_path=SAVE_PATH):\n        self.model = BertForSequenceClassification.from_pretrained(model_path)\n        self.tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        self.model_save_path=model_save_path\n        self.max_len = MAX_LEN\n        self.epochs = epochs\n        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n        self.model.to(self.device)\n        \n    def preparation(self, X_train, y_train, X_valid, y_valid):\n    # create datasets\n        self.train_set = CustomDataset(X_train, y_train, self.tokenizer)\n        self.valid_set = CustomDataset(X_valid, y_valid, self.tokenizer)\n\n    # create data loaders\n        self.train_loader = DataLoader(self.train_set, batch_size=BATCH_SIZE, shuffle=True)\n        self.valid_loader = DataLoader(self.valid_set, batch_size=1, shuffle=True)\n\n    # helpers initialization\n        self.optimizer = AdamW(self.model.parameters(), lr=2e-5, correct_bias=False)\n        self.scheduler = get_linear_schedule_with_warmup(\n            self.optimizer,\n            num_warmup_steps=0,\n            num_training_steps=len(self.train_loader) * self.epochs\n            )\n        self.loss_fn = torch.nn.CrossEntropyLoss().to(self.device)\n    \n    def fit(self):\n        self.model = self.model.train()\n        losses = []\n        correct_predictions = 0\n\n        for data in self.train_loader:\n            input_ids = data[\"input_ids\"].to(self.device)\n            attention_mask = data[\"attention_mask\"].to(self.device)\n            targets = data[\"targets\"].to(self.device)\n\n            outputs = self.model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n\n            preds = torch.argmax(outputs.logits, dim=1)\n            loss = self.loss_fn(outputs.logits, targets)\n\n            correct_predictions += torch.sum(preds == targets)\n\n            losses.append(loss.item())\n        \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n            self.optimizer.step()\n            self.scheduler.step()\n            self.optimizer.zero_grad()\n\n        train_acc = correct_predictions.double() / len(self.train_set)\n        train_loss = np.mean(losses)\n        \n        return train_acc, train_loss\n    \n    def eval(self):\n        self.model = self.model.eval()\n        losses = []\n        correct_predictions = 0\n\n        with torch.no_grad():\n            for data in self.valid_loader:\n                input_ids = data[\"input_ids\"].to(self.device)\n                attention_mask = data[\"attention_mask\"].to(self.device)\n                targets = data[\"targets\"].to(self.device)\n\n                outputs = self.model(\n                    input_ids=input_ids,\n                    attention_mask=attention_mask\n                    )\n\n                preds = torch.argmax(outputs.logits, dim=1)\n                loss = self.loss_fn(outputs.logits, targets)\n                correct_predictions += torch.sum(preds == targets)\n                losses.append(loss.item())\n    \n        val_acc = correct_predictions.double() / len(self.valid_set)\n        val_loss = np.mean(losses)\n        return val_acc, val_loss\n    \n    def train(self):\n        best_accuracy = 0\n        for epoch in range(self.epochs):\n            print(f'Epoch {epoch + 1}/{self.epochs}')\n            train_acc, train_loss = self.fit()\n            print(f'Train loss {train_loss} accuracy {train_acc}')\n\n            val_acc, val_loss = self.eval()\n            print(f'Val loss {val_loss} accuracy {val_acc}')\n            print('-' * 10)\n\n            if val_acc > best_accuracy:\n                torch.save(self.model, self.model_save_path)\n                best_accuracy = val_acc\n\n        self.model = torch.load(self.model_save_path)\n        \n    \n    def predict(self, text):\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            truncation=True,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n    \n        out = {\n              'text': text,\n              'input_ids': encoding['input_ids'].flatten(),\n              'attention_mask': encoding['attention_mask'].flatten()\n          }\n    \n        input_ids = out[\"input_ids\"].to(self.device)\n        attention_mask = out[\"attention_mask\"].to(self.device)\n    \n        outputs = self.model(\n            input_ids=input_ids.unsqueeze(0),\n            attention_mask=attention_mask.unsqueeze(0)\n        )\n    \n        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n\n        return prediction\n        ","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:51:07.030944Z","iopub.execute_input":"2024-01-07T09:51:07.031398Z","iopub.status.idle":"2024-01-07T09:51:07.056965Z","shell.execute_reply.started":"2024-01-07T09:51:07.031363Z","shell.execute_reply":"2024-01-07T09:51:07.055936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tinybert = BertClassifier()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:28:42.314895Z","iopub.execute_input":"2024-01-07T09:28:42.315576Z","iopub.status.idle":"2024-01-07T09:28:43.195565Z","shell.execute_reply.started":"2024-01-07T09:28:42.315544Z","shell.execute_reply":"2024-01-07T09:28:43.194739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tinybert.preparation(\n        X_train=list(data_train['text']),\n        y_train=list(data_train['target']),\n        X_valid=list(data_test['text']),\n        y_valid=list(data_test['target'])\n    )","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:44:37.774192Z","iopub.execute_input":"2024-01-07T09:44:37.774585Z","iopub.status.idle":"2024-01-07T09:44:37.839566Z","shell.execute_reply.started":"2024-01-07T09:44:37.774556Z","shell.execute_reply":"2024-01-07T09:44:37.838635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tinybert.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:41:08.127617Z","iopub.execute_input":"2024-01-07T09:41:08.128038Z","iopub.status.idle":"2024-01-07T09:41:08.217458Z","shell.execute_reply.started":"2024-01-07T09:41:08.128008Z","shell.execute_reply":"2024-01-07T09:41:08.216224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = test_news['content'].apply(lambda x: tinybert.predict(x))\nnew = pd.DataFrame()\nnew['topic'] = pd.Series(res)\nnew.index.rename('index', inplace=True)\nnew.to_csv('tinybert_fin.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-07T08:56:44.319630Z","iopub.execute_input":"2024-01-07T08:56:44.319983Z","iopub.status.idle":"2024-01-07T09:13:22.219480Z","shell.execute_reply.started":"2024-01-07T08:56:44.319953Z","shell.execute_reply":"2024-01-07T09:13:22.218119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = data_test['text'].apply(lambda x: tinybert.predict(x))\nprint(classification_report(data_test['target'], preds))","metadata":{"execution":{"iopub.status.busy":"2024-01-07T09:28:55.529505Z","iopub.execute_input":"2024-01-07T09:28:55.530138Z","iopub.status.idle":"2024-01-07T09:37:57.983386Z","shell.execute_reply.started":"2024-01-07T09:28:55.530110Z","shell.execute_reply":"2024-01-07T09:37:57.982366Z"},"trusted":true},"execution_count":null,"outputs":[]}]}